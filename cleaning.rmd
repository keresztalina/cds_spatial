---
title: "cleaning"
author: "Alina Kereszt"
date: "`r Sys.Date()`"
output: html_document
---

```{r, include=FALSE}
# install packages
# options("install.lock"=FALSE)
# install.packages("tidyverse")
```

```{r, include=FALSE}
# load packages
library(tidyverse)
```

The purpose of this script is to preprocess the data involved in this project, part of the Spatial Data Science course in the S23 Cultural Data Science elective at Aarhus University. This project seeks to search an inventory of flats for sale in Budapest, Hungary, based on a number of different criteria. In order for the sake of simplicity and because the searched parameters are often not directly relevant to spatial analysis, some parameters, that in real life would be important, have been removed.

# Preprocess 'flats.csv'
## Load data
The data is first loaded.
```{r}
flats <- read.csv("data/flats.csv")
```

## Remove unnecessary columns
Some columns are unnecessary for the purpose of this analysis. These are removed.
```{r}
flats <- flats %>% 
  dplyr::select(!c(X, 
            common_cost,
            date_scraped,
            description,
            energy_certificate,
            furniture,
            garden,
            heating_type,
            image_folder_name,
            image_urls,
            title,
            type,
            view_type))
```

## Translation-type transformations
The remaining columns contain information in Hungarian. In order to be more understandable in an English-language course, I am translating this information into English. I am also making any necessary transformations to data format.

Transforming the 'animals' column.
```{r}
# convert to factor
flats$animals <- as.factor(flats$animals)

# convert contents to English
levels(flats$animals) <- c(NA, 
                           "only small pets", 
                           "yes", 
                           "no")
```

Transforming the 'condition' column.
```{r}
# convert to factor
flats$condition <- as.factor(flats$condition)

# convert contents to English
levels(flats$condition) <- c(NA, 
                             "in need of renovation", 
                             "renovated", 
                             "good",
                             "newly built",
                             "like new")
```

Transforming the 'elevator' column.
```{r}
# convert to factor
flats$elevator <- as.factor(flats$elevator)

# convert contents to English
levels(flats$elevator) <- c(NA, 
                            "no",
                            "yes")
```

## Numeric-type transformations
Ensuring appropriate encoding of numeric columns.
```{r}
flats$price <- as.numeric(flats$price)
flats$rooms <- as.numeric(flats$rooms)
flats$size <- as.numeric(flats$size)
```

Removing NAs from numeric columns - factors like price are central to this analysis.
```{r}
flats <- flats %>% 
  filter(!is.na(price)) %>% 
  filter(!is.na(rooms)) %>% 
  filter(!is.na(size))
```

With regard to price, there are also some likely erroneous values listed. Flats are unlikely to cost e.g. 120 HUF per month (the lowest value in the dataset - equivalent to 2.5 DKK), nor e.g. 136 377 450 HUF (the highest value in the dataset - equivalent to 2 607 351 DKK). I have decided to set a minimum of 50 000 HUF and a maximum of 2 000 000 HUF. There is also a similar problem with flat sizes - the largest is listed as being 45 000 m2, so I have capped flat size at 500 m2.
```{r}
flats <- flats %>% 
  filter(price >= 50000 & price <= 2000000) %>% 
  filter(size <= 500)
```


The coordinates for each apartment are listed within a single cell. For easier handling, the coordinates are split into latitude and longitude.
```{r}
# separate into 2 columns by comma
flats <- flats %>% 
  separate_wider_delim(location, 
                       delim = ",", 
                       names = c("latitude", 
                                 "longitude"))

# clean of unnecessary characters
flats$latitude <- gsub("\\(",
                       "",
                       flats$latitude)
flats$longitude <- gsub("\\)",
                        "",
                        flats$longitude)

names(flats)[names(flats) == "latitude"] <- "lat"
names(flats)[names(flats) == "longitude"] <- "lon"

# ensure appropriate encoding
flats$lat <- as.numeric(flats$lat)
flats$lon <- as.numeric(flats$lon)
```

The administrative divisions of Budapest are numbered. Here, these numbers are extracted.
```{r}
flats$location_str <- gsub("Budapest, ",
                           "",
                           flats$location_str)
flats$location_str <- gsub(". kerÃ¼let,* *.*",
                           "",
                           flats$location_str)
flats$location_str <- gsub(" ",
                           "",
                           flats$location_str)

flats$location_str <- as.roman(flats$location_str)
flats$location_str <- as.numeric(flats$location_str)

names(flats)[names(flats) == "location_str"] <- "quarter"
```

## Save as new file
This is so that the preprocessing code only needs to be run once.
```{r}
write.csv(flats, 
          "data/flats_revised.csv",
          row.names = FALSE)
```

# Preprocess public transport data
## Load data
The data is first loaded.
```{r}
stops <- read.csv("data/stops.txt")
stop_times <- read.csv("data/stop_times.txt")
trips <- read.csv("data/trips.txt")
routes <- read.csv("data/routes.txt")
```

## Select necessary variables
Not all the variables are needed for our analysis, so only the most necessary are kept for ease of data wrangling.
```{r}
s <- stops %>% 
  select(stop_id,
         stop_name,
         stop_lat,
         stop_lon)
rm(stops)
```

```{r}
r <- routes %>% 
  select(route_id,
         route_short_name,
         route_type)
rm(routes) # remove unnecessary data frame

# convert variable to factor for easier processing
r$route_type <- as.factor(r$route_type)

# define levels
levels(r$route_type) <- c("tram",
                          "metro",
                          "bus",
                          "ship",
                          "trolleybus",
                          "commuter rail")
```

```{r}
t <- trips %>% 
  select(route_id,
         trip_id) 
rm(trips) # remove unnecessary data frame
```

```{r}
st <- stop_times %>% 
  select(trip_id,
         stop_id)
rm(stop_times) # remove unnecessary data frame
```

## Pull data together
The data needed for our analysis is divided among four data frames, which need to be pulled together. Sometimes, certain variables do not find their correspondences, resulting in NAs. These rows are always removed. This results in some loss of data, but the relative quantity of rows containing NAs is always negligible.
```{r}
# join data of stops with data of trips
df <- left_join(s, st)
df <- df %>% 
  filter(!is.na(trip_id))
rm(s) # remove unnecessary data frame
rm(st) # remove unnecessary data frame

# join with data of possible routes
df <- left_join(df, t)
rm(t) # remove unnecessary data frame

# join with data of route info
df <- left_join(df, r)
```

Unnecessary columns (used only for pulling data together) are removed and unique rows are kept.
```{r}
df2 <- df %>% 
  select(!c(stop_id,
            trip_id, 
            route_id))
df2 <- unique(df2)
```

```{r}
df_new <- df2 %>%
  group_by(stop_name, stop_lat, stop_lon, route_type) %>%
  summarize(route_count = n_distinct(route_short_name))
```


Sometimes, the same stop for different directions of a route is located on opposite sides of the street. Since we do not want them to be counted as separate stops (as they are essentially the same stop split into two), the mean of their coordinates is taken.
```{r}
stops_cleaned <- df_new %>% 
  group_by(stop_name, route_type) %>% 
  summarise(lat = mean(stop_lat),
            lon = mean(stop_lon),
            routes = sum(route_count))
```

## Save cleaned data
In order to only run the preprocessing once, the preprocessed data is saved.
```{r}
write.csv(stops_cleaned, 
          "data/stops_revised.csv")
```





























